{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第四题：实现K-means\n",
    "\n",
    "实验内容：\n",
    "1. 实现一个K-means聚类算法\n",
    "2. 计算外部指标FMI和NMI\n",
    "3. 对聚类结果可视化\n",
    "4. 完成第二个数据集上myKmeans与层次聚类(single)算法的对比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们要实现一个K-means算法，也称为原型聚类算法。\n",
    "\n",
    "## 初始化\n",
    "\n",
    "K-means在实现的时候，首先需要选取类簇中心。类簇中心的选取方法有很多，我们这里使用最简单的方法，随机选取。也就是，从给定的待聚类的样本中，随机选取 $K$ 个样本，作为 $K$ 个类簇的中心。\n",
    "\n",
    "## 优化\n",
    "\n",
    "选取类中心后，就需要不断的调成类中心的位置，开始优化过程，优化主要分为两步：\n",
    "\n",
    "### 第一步\n",
    "\n",
    "计算所有样本到 $K$ 个类中心的距离。每个样本，选择距自己最近的类中心作为自己属于的类簇。（这里的距离我们选择欧式距离）\n",
    "\n",
    "### 第二步\n",
    "\n",
    "针对第一步分出来的 $K$ 个类簇，计算每个类簇内样本的均值，将计算得到的 $K$ 个均值向量，作为这 $K$ 个类簇新的中心。\n",
    "\n",
    "### 然后循环第一步和第二步，直至一定的迭代次数，或类中心无显著的位置改变为止。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 导入模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 生成数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "X, y = make_blobs(n_samples = 1500, random_state = 170)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里的X和y分别代表样本和对应的真实标记。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用plt.scatter绘制散点图，参数c是一个`np.ndarray`，表示类别，相同的值会有相同的颜色。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 欧式距离的实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定向量 $x \\in \\mathbb{R}^m$，$y \\in \\mathbb{R}^m$，两个向量的欧式距离定义为：\n",
    "\n",
    "$$\n",
    "E(x, y) = \\sqrt{\\sum^m_{i = 1} (x_i - y_i)^2}\n",
    "$$\n",
    "\n",
    "其中, $i$ 表示向量的第 $i$ 个分量。\n",
    "\n",
    "我们要实现一个可以计算多个样本组成的矩阵 $X$，与某一个类中心 $y$ 之间欧氏距离的函数。\n",
    "\n",
    "给定输入矩阵 $X \\in \\mathbb{R}^{n \\times m}$，其中 $n$ 是样本数，$m$ 是特征数，给定输入的类簇中心 $y \\in \\mathbb{R}^m$。\n",
    "\n",
    "我们要计算 $n$ 个样本到某一类簇中心 $y$ 的欧式距离，最后的结果是 $E \\in \\mathbb{R}^{n}$，每个元素表示矩阵 $X$ 中的每个样本到类中心 $y$ 的欧式距离。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_distance(X, y):\n",
    "    '''\n",
    "    计算样本矩阵X与类中心y之间的欧氏距离\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X, np.ndarray, 样本矩阵 X, 维度：(n, m)\n",
    "    \n",
    "    y, np.ndarray, 类中心 y，维度：(m, )\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    distance, np.ndarray, 样本矩阵 X 每个样本到类中心 y 之间的欧式距离，维度：(n, )\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    distance = \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试样例\n",
    "print(compute_distance(np.array([[0, 0], [0, 1]]), np.array([0, 1]))) # [ 1.  0.]\n",
    "print(compute_distance(np.array([[0, 0], [0, 1]]), np.array([1, 1]))) # [ 1.41421356  1.        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面开始实现K-means聚类算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class myKmeans:\n",
    "    def __init__(self, n_clusters, max_iter = 100):\n",
    "        '''\n",
    "        初始化，三个成员变量\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_clusters: int, 类簇的个数\n",
    "        \n",
    "        max_iter, int, default 100, 最大迭代轮数，默认为100\n",
    "        \n",
    "        '''\n",
    "        # 表示类簇的个数\n",
    "        self.n_clusters = n_clusters\n",
    "        \n",
    "        # 表示最大迭代次数\n",
    "        self.max_iter = int(max_iter)\n",
    "        \n",
    "        # 类簇中心\n",
    "        self.centroids = None\n",
    "    \n",
    "    def choose_centroid(self, X):\n",
    "        '''\n",
    "        选取类簇中心\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: np.ndarray, 样本矩阵X，维度：(n, m)\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        centroids: np.ndarray, 维度：(n_clusters, m)\n",
    "        \n",
    "        '''\n",
    "        centroids = X[np.random.choice(np.arange(len(X)), self.n_clusters, replace = False), :]\n",
    "        return centroids\n",
    "    \n",
    "    def compute_label(self, X):\n",
    "        '''\n",
    "        给定样本矩阵X，结合类中心矩阵self.centroids，计算样本矩阵X内每个样本属于哪个类簇\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: np.ndarray, 样本矩阵X，维度：(n, m)\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        labels: np.ndarray, 维度：(n, )\n",
    "        \n",
    "        '''\n",
    "        # 将每个样本到每个类簇中心的距离存储在distances中，每行表示当前样本对于不同的类中心的距离\n",
    "        distances = np.empty((len(X), self.n_clusters))\n",
    "        \n",
    "        # 遍历类中心，对每个类中心，计算所有的样本到这个类中心的距离\n",
    "        for index in range(len(self.centroids)):\n",
    "            \n",
    "            # 计算样本矩阵X所有样本到当前类中心的距离，存储在distances中的第index列中\n",
    "            # YOUR CODE HERE\n",
    "            distances[:, index] = \n",
    "            \n",
    "        # 取distances每行最小值的下标，这个下标就是这个样本属于的类簇的标记\n",
    "        # YOUR CODE HERE\n",
    "        labels = \n",
    "        \n",
    "        # 返回每个样本属于的类簇的标记\n",
    "        return labels\n",
    "    \n",
    "    def fit(self, X):\n",
    "        '''\n",
    "        聚类，包含类中心初始化，类中心优化两个部分\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: np.ndarray, 样本矩阵X，维度：(n, m)\n",
    "        \n",
    "        '''\n",
    "        # 类中心随机初始化\n",
    "        self.centroids = self.choose_centroid(X)\n",
    "        \n",
    "        # 优化self.max_iter轮\n",
    "        for epoch in range(self.max_iter):\n",
    "            \n",
    "            # 计算当前所有样本的属于哪个类簇\n",
    "            labels = self.compute_label(X)\n",
    "            \n",
    "            # 重新计算每个类簇的类中心\n",
    "            for index in range(self.n_clusters):\n",
    "                \n",
    "                # 重新计算第 index 个类中心，对属于这个类簇的样本取均值\n",
    "                # YOUR CODE HERE\n",
    "                self.centroids[index, :] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 初始化一个3类簇的模型\n",
    "model = myKmeans(3)\n",
    "\n",
    "# 对X进行聚类，计算类中心\n",
    "model.fit(X)\n",
    "\n",
    "# 计算X的类标记\n",
    "prediction = model.compute_label(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 聚类结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用我们的预测结果上色\n",
    "plt.scatter(X[:, 0], X[:, 1], c = prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 评价指标\n",
    "\n",
    "这里，我们选用两个外部指标，FMI和NMI。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.metrics import fowlkes_mallows_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_mutual_info_score(y, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fowlkes_mallows_score(y, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到这两个外部指标都为1，说明聚类效果和给出的参考模型一致。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "使用下面提供的数据，完成以下实验：\n",
    "1. 使用myKmeans和层次聚类算法(AgglomerativeClustering)对该数据进行聚类。\n",
    "2. 计算出两个模型的FMI和NMI值，并对聚类结果可视化。\n",
    "3. 分析为什么两个模型的聚类效果会出现如此的不同。\n",
    "\n",
    "要求：\n",
    "1. **层次聚类的连接方式选择'single'，即使用两个类簇之间的最小距离**\n",
    "2. **类簇个数设定为2**\n",
    "\n",
    "完成下表的填写：\n",
    "\n",
    "###### 双击此处填写\n",
    "\n",
    "算法|FMI|NMI\n",
    "-|-|-\n",
    "myKmeans|0.0|0.0\n",
    "AgglomerativeClustering|0.0|0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "X, y = make_circles(n_samples = 1500, factor = .5, noise = .05, random_state = 32)\n",
    "plt.scatter(X[:, 0], X[:, 1], c = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
